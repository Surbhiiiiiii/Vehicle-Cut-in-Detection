{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74di8pN5kPyD"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "\n",
        "# Load YOLOv5 model from PyTorch Hub\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
        "\n",
        "# Initialize tracker\n",
        "class SimpleTracker:\n",
        "    def __init__(self):\n",
        "        self.trackers = []\n",
        "\n",
        "    def update(self, detections):\n",
        "        for tracker in self.trackers:\n",
        "            tracker['lost'] += 1\n",
        "\n",
        "        for detection in detections:\n",
        "            x1, y1, x2, y2, conf, cls = detection\n",
        "            matched = False\n",
        "            for tracker in self.trackers:\n",
        "                if self.iou(tracker['bbox'], [x1, y1, x2, y2]) > 0.5:\n",
        "                    tracker['bbox'] = [x1, y1, x2, y2]\n",
        "                    tracker['lost'] = 0\n",
        "                    matched = True\n",
        "                    break\n",
        "            if not matched:\n",
        "                self.trackers.append({'bbox': [x1, y1, x2, y2], 'lost': 0})\n",
        "\n",
        "        self.trackers = [t for t in self.trackers if t['lost'] < 5]\n",
        "\n",
        "        return self.trackers\n",
        "\n",
        "    def iou(self, bbox1, bbox2):\n",
        "        x1, y1, x2, y2 = bbox1\n",
        "        x1_, y1_, x2_, y2_ = bbox2\n",
        "\n",
        "        xi1, yi1 = max(x1, x1_), max(y1, y1_)\n",
        "        xi2, yi2 = min(x2, x2_), min(y2, y2_)\n",
        "\n",
        "        inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
        "\n",
        "        bbox1_area = (x2 - x1) * (y2 - y1)\n",
        "        bbox2_area = (x2_ - x1_) * (y2_ - y1_)\n",
        "\n",
        "        union_area = bbox1_area + bbox2_area - inter_area\n",
        "\n",
        "        return inter_area / union_area\n",
        "\n",
        "# Calculate Euclidean distance between two vehicles\n",
        "def calculate_distance(vehicle1, vehicle2):\n",
        "    pos1 = np.array(vehicle1['center'])\n",
        "    pos2 = np.array(vehicle2['center'])\n",
        "    distance = np.linalg.norm(pos1 - pos2)\n",
        "    return distance\n",
        "\n",
        "# Process video frames\n",
        "def process_video(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    tracker = SimpleTracker()\n",
        "    vehicle_tracks = {}\n",
        "    warning_distance = 50  # Threshold distance in pixels\n",
        "\n",
        "    # Define the codec and create VideoWriter object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter('output_with_warnings.mp4', fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        results = model(frame)\n",
        "        detections = []\n",
        "        for *box, conf, cls in results.xyxy[0].cpu().numpy():\n",
        "            if cls == 2:  # Only consider cars\n",
        "                detections.append(box + [conf, cls])\n",
        "\n",
        "        tracks = tracker.update(detections)\n",
        "\n",
        "        for i, track in enumerate(tracks):\n",
        "            x1, y1, x2, y2 = map(int, track['bbox'])\n",
        "            center = [(x1 + x2) / 2, (y1 + y2) / 2]\n",
        "            track['center'] = center\n",
        "            if i not in vehicle_tracks:\n",
        "                vehicle_tracks[i] = deque(maxlen=5)\n",
        "            vehicle_tracks[i].append(center)\n",
        "            if len(vehicle_tracks[i]) > 1:\n",
        "                track['velocity'] = np.mean(np.diff(vehicle_tracks[i], axis=0), axis=0)\n",
        "            else:\n",
        "                track['velocity'] = np.array([0, 0])\n",
        "\n",
        "            # Draw bounding box and center\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.circle(frame, (int(center[0]), int(center[1])), 2, (0, 0, 255), -1)\n",
        "            cv2.putText(frame, f'ID: {i}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "        for i, track in enumerate(tracks):\n",
        "            for j, other_track in enumerate(tracks):\n",
        "                if i != j:\n",
        "                    distance = calculate_distance(track, other_track)\n",
        "                    if distance < warning_distance:\n",
        "                        cv2.putText(frame, f'Warning! Vehicles {i} and {j} too close!', (50, 50 + 30*i), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    video_path = '/content/sample_data/WhatsApp Video 2024-07-05 at 17.25.04_ac24697e.mp4'  # Replace with your local video file path\n",
        "    process_video(video_path)\n"
      ]
    }
  ]
}